ğŸ›  Tool-Executing Agent (Local LLM, CPU-First)

A deterministic, tool-executing AI agent built in pure Python that decides when to use tools vs when to use an LLM, running entirely on CPU using Ollama.

This project demonstrates production-grade agent fundamentals without heavy frameworks.

---

ğŸš€ What This Project Does

The agent:

Accepts natural language input

Decides whether a tool is required

Executes the tool deterministically

Falls back to an LLM when no tool is needed

---

Supported Tools

ğŸ§® Calculator (safe expression evaluation)

â° Current time tool

LLM

Local LLM via Ollama

No OpenAI / no cloud dependency

CPU-first design

---

ğŸ“‚ Project Structure
tool-executing-agent/
â”‚
â”œâ”€â”€ agent/
â”‚ â”œâ”€â”€ agent.py # Core agent logic
â”‚ â”œâ”€â”€ parser.py # Input parsing & routing helpers
â”‚ â””â”€â”€ prompt.txt # System prompt (LLM discipline)
â”‚
â”œâ”€â”€ llm/
â”‚ â”œâ”€â”€ ollama_llm.py # Ollama LLM wrapper
â”‚ â””â”€â”€ mock_llm.py # Mock LLM for testing
â”‚
â”œâ”€â”€ tools/
â”‚ â”œâ”€â”€ calculator.py # Calculator tool
â”‚ â””â”€â”€ time_tool.py # Time tool
â”‚
â”œâ”€â”€ test_agent.py # Manual test runner
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .env

---

ğŸ§  How the Agent Works
1ï¸âƒ£ Tool Decision

The agent inspects the user input and determines:

Tool required? â†’ Execute tool

No tool needed? â†’ Use LLM

"What is 25 \* (3 + 7)?" â†’ Calculator
"What time is it now?" â†’ Time tool
"What is capital of America?" â†’ LLM

2ï¸âƒ£ Deterministic Tool Execution

Mathematical expressions are extracted and validated

Parentheses are balanced

Only safe characters are allowed

Tools are executed without LLM hallucination

3ï¸âƒ£ LLM Fallback

If no tool applies:

Prompt is sent to local Ollama model

Response is returned directly

---

ğŸ§ª Example Output
$ python test_agent.py

The current time is 11:58.
The result is 250.
Washington, D.C. is the capital of the United States.

---

âš™ï¸ Setup Instructions

1ï¸âƒ£ Create Virtual Environment
python -m venv .venv_toolexecutingagent
source .venv_toolexecutingagent/bin/activate

2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

3ï¸âƒ£ Run Ollama

Ensure Ollama is running with a model installed:

ollama run llama3

4ï¸âƒ£ Run Tests
python test_agent.py

---
